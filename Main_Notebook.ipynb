{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdZXpgxdLmexYlHRLTPQNZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nelsontorresjr330/CS5265-Repo/blob/main/Main_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 1 Assignment\n"
      ],
      "metadata": {
        "id": "GfHg13BOjk7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proposed Project - NFL Data to predict future games"
      ],
      "metadata": {
        "id": "pyR7KVNfkyVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background \n",
        "### I am a huge sports fan (NFL and Soccer mostly) & luckily for me there is a ton of readily available data online for all fans to use. The dataset I chose uses Football data to start but I could see myself dabbling in other sports later on.\n",
        "### There are tons of available scholarly articles & professionals who dedicate their lives to determining game results. Its ultimately impossible to perfectly predict every game though as there are essentially infinite variables to consider but I believe there is some fun/opportunity in trying to get as accurate as possible. One example of someone using data to try and predict results is https://www.activestate.com/blog/how-to-predict-nfl-winners-with-python/ . I will be referencing this one throughout the semester most likely as its broken down clearly and easy to digest.\n"
      ],
      "metadata": {
        "id": "2Y1aLINplAIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Description\n",
        "### The final goal for my project is to reach around 60% accuracy on game predictions, the specific dataset I plan on using is provided by FiveThirtyEight (https://data.fivethirtyeight.com/). Their nfl-elo dataset hosts 17380 rows and 33 columns with date, boolean, integer, string, and float data types. To fit the assignment description a bit better I can widdle down the number of columns since I dont think they will all be necessary.\n",
        "### My plan in a nutshell is essentially to weigh the columns initally in terms of how I believe they contribute to the final score, then let the modeling algorithm grow from their and discover the weights on it's own. \n",
        "### To me, the most important stats are: \n",
        "- playoff (BOOL : Whether or not the game was a playoff game)\n",
        "- elo_pre scores (FLOAT : Overall team rating going into the games)\n",
        "- elo_prob scores (FLOAT: A teams chance of winning based solely on their elo)\n",
        "- qbelo_pre scores (FLOAT : Overall QB rating going into the games)\n",
        "- qbelo_prob scores (FLOAT : A teams chance of winning based solely on their QB Elo)\n",
        "- qbelo_post scores (FLOAT : A QB rating after the given games) \n",
        "- quality (INT : A game's quality score based on the teams' pregame elo ratings, scaled from 0-100)\n",
        "- importance (INT : Rating of games importance based on how the result would affect the models foraecasted playoff odds, scaled from 0-100)\n",
        "- total_rating (INT : The average of quality and importance)\n",
        "\n",
        "### For a description of all the columns -> https://github.com/fivethirtyeight/data/tree/master/nfl-elo"
      ],
      "metadata": {
        "id": "FXilSl3AlDsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Metric \n",
        "### The dataset provides data as of February 2023 or the end of the most recent NFL season. To determine how well my model works, I will compare the model's predicted score to the true end result and the closer the model is to the actual score, the better the model. Ideally, my model will be able to predict around 60% of the games correctly.\n",
        "### Initially, the goal is just to get a win or loss model working, then compare the predicted results to the actual ones and once satisfied with those, I will move on to predicting scores outright.\n",
        "# Total Accuracy Percentage = Σ(games_predicted_correctly) / Σ(all_games_predicted) \n"
      ],
      "metadata": {
        "id": "sDeVP6pWoJQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3 Assignment"
      ],
      "metadata": {
        "id": "jnx9vWaYi_ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA\n",
        "\n"
      ],
      "metadata": {
        "id": "ii9Pb0yWjFib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions\n",
        "\n",
        "\n",
        "*   Which teams are most consistant in terms of following their predicted scores?\n",
        "*   How well can someone get their algorithm to predict games?\n",
        "*   At which point is data no longer useful for current teams?\n",
        "*   Are win / loss streaks a major factor in a team's performance? "
      ],
      "metadata": {
        "id": "RUJM0WiojLWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tables and Visualizations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "96tF0-y5kYhD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initial DF\n",
        "url = 'https://raw.githubusercontent.com/Nelsontorresjr330/CS5265-Repo/main/nfl_elo.csv'\n",
        "raw_df = pd.read_csv(url, index_col=0)\n",
        "raw_df.columns"
      ],
      "metadata": {
        "id": "Qo1SKweAk6bu",
        "outputId": "95329203-ab7d-4d6b-d7b1-f8928e8a2210",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['season', 'neutral', 'playoff', 'team1', 'team2', 'elo1_pre',\n",
              "       'elo2_pre', 'elo_prob1', 'elo_prob2', 'elo1_post', 'elo2_post',\n",
              "       'qbelo1_pre', 'qbelo2_pre', 'qb1', 'qb2', 'qb1_value_pre',\n",
              "       'qb2_value_pre', 'qb1_adj', 'qb2_adj', 'qbelo_prob1', 'qbelo_prob2',\n",
              "       'qb1_game_value', 'qb2_game_value', 'qb1_value_post', 'qb2_value_post',\n",
              "       'qbelo1_post', 'qbelo2_post', 'score1', 'score2', 'quality',\n",
              "       'importance', 'total_rating'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Elo-Based Favorites\n",
        "#Since the data doesn't provide explicit favorites as a column,\n",
        "#I'll add one based on the team's elos probability, the team with\n",
        "#The greater elo_prob is the favorite\n",
        "\n",
        "df_w_fav = raw_df.copy()\n",
        "df_w_fav['Favorite'] = np.where(raw_df['elo_prob1'] >= raw_df['elo_prob2'], raw_df['team1'], raw_df['team2'])\n",
        "print(df_w_fav[['team1','team2','elo_prob1','elo_prob2','Favorite']])"
      ],
      "metadata": {
        "id": "aEax-ikSlPJO",
        "outputId": "00e685e3-8cd8-4aa5-e4e2-9f34492cdcfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           team1 team2  elo_prob1  elo_prob2 Favorite\n",
            "date                                                 \n",
            "1920-09-26   RII   STP   0.824651   0.175349      RII\n",
            "1920-10-03   AKR   WHE   0.824212   0.175788      AKR\n",
            "1920-10-03   BFF   WBU   0.802000   0.198000      BFF\n",
            "1920-10-03   DAY   COL   0.575819   0.424181      DAY\n",
            "1920-10-03   RII   MUN   0.644171   0.355829      RII\n",
            "...          ...   ...        ...        ...      ...\n",
            "2023-01-22   BUF   CIN   0.648277   0.351723      BUF\n",
            "2023-01-22    SF   DAL   0.683613   0.316387       SF\n",
            "2023-01-29   PHI    SF   0.450672   0.549328       SF\n",
            "2023-01-29    KC   CIN   0.600966   0.399034       KC\n",
            "2023-02-12   PHI    KC   0.375176   0.624824       KC\n",
            "\n",
            "[17379 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Favored Team Win\n",
        "#Another additional column for if the favored team won, as a Boolean\n",
        "\n",
        "df_w_fav_win = df_w_fav.copy()\n",
        "df_w_fav_win['Favorite_won'] = np.where((((df_w_fav['team1'] == df_w_fav['Favorite']) & (df_w_fav['score1'] > df_w_fav['score2'])) | ((df_w_fav['team2'] == df_w_fav['Favorite']) & (df_w_fav['score2'] > df_w_fav['score1']))), True, False) \n",
        "print(df_w_fav_win[['team1','team2','Favorite','score1','score2','Favorite_won']])"
      ],
      "metadata": {
        "id": "1rEkjT8Loxfg",
        "outputId": "1f8905d4-56ec-4d1e-bdf2-a8682dff0b73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           team1 team2 Favorite  score1  score2  Favorite_won\n",
            "date                                                         \n",
            "1920-09-26   RII   STP      RII      48       0          True\n",
            "1920-10-03   AKR   WHE      AKR      43       0          True\n",
            "1920-10-03   BFF   WBU      BFF      32       6          True\n",
            "1920-10-03   DAY   COL      DAY      14       0          True\n",
            "1920-10-03   RII   MUN      RII      45       0          True\n",
            "...          ...   ...      ...     ...     ...           ...\n",
            "2023-01-22   BUF   CIN      BUF      10      27         False\n",
            "2023-01-22    SF   DAL       SF      19      12          True\n",
            "2023-01-29   PHI    SF       SF      31       7         False\n",
            "2023-01-29    KC   CIN       KC      23      20          True\n",
            "2023-02-12   PHI    KC       KC      35      38          True\n",
            "\n",
            "[17379 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Next get the total count of times each team was favorited and won & divide it by the total times they were favorited\n",
        "\n",
        "total_favorites = df_w_fav_win['Favorite'].value_counts()\n",
        "favorites_won = df_w_fav_win.loc[df_w_fav_win['Favorite_won']==True].groupby('Favorite')['Favorite_won'].count()\n",
        "favs_percents = favorites_won / total_favorites\n",
        "favs_percents.dropna().sort_values()#['TEN'] #You can index by any team you'd like to see"
      ],
      "metadata": {
        "id": "RxVbO3fHqne5",
        "outputId": "d496acfb-8280-40fc-9e08-705358b6415a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LOU    0.250000\n",
              "NYA    0.285714\n",
              "TOR    0.285714\n",
              "CRA    0.307692\n",
              "DHR    0.333333\n",
              "         ...   \n",
              "DWL    1.000000\n",
              "LAB    1.000000\n",
              "KCB    1.000000\n",
              "SLA    1.000000\n",
              "CHT    1.000000\n",
              "Length: 74, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Future Engineering\n",
        "Even with just this quick test to see the most consistant teams, I can see a few columns I need to add to help out / already added. I added a few already (Favorites, Favorites_Won, Favs_Percents) but another one I might need is something along the lines of \"QB still on team\", \"Team currently in NFL\" or \"Team still mostly in NFL\". Most of these are just to make sure the predictions for future games are accurate but might not be completely accurate since to make predictions I can basically assume they're all true. Still I imagine many more random columns will come along the way.\n",
        "\n",
        "### Train/Test Split\n",
        "I'm not entirely certain on my ideal Train Test Split but I believe what I would like to do to start off is train my model with every season prior to 2020 and test it with the 2021 and 2022 seasons. Each NFL season has about 250 or so games so this should provide about 16,500 games of training and 500 of testing. This probably isnt the greatest split but its where I would like to start since I'm only really interested in predicting recent/upcoming games.\n",
        "\n",
        "### Initial Pipeline\n",
        "I am also not entirely certain on the exact specifics for the pipeline but I do know there will be a handful of operations necessary in the pipeline, I'm just not sure how to go about implementing them. For example, the older NFL data does not provide, for example there are no QB elo stats prior to 1950 so all of those columns, if I intend to use the data prior to 1950, must be ran through Imputers. As mentioned before, there are already a handful of calculations and features I've implemented that will need to go through column transformers. There may be other parts I need to add to the pipeline later on but as of now this is all I can think of and then the final model fitting part of the pipeline.\n",
        "\n",
        "### Model Fitting and Evaluation\n",
        "After going through this assignment, I feel very confident in my future model. I believe I'll be able to hit my personal goals for the model. Some assumptions I have about the features are:\n",
        "\n",
        "*   The model will rely heavily on the Pre_Elo values instead of features added onto it\n",
        "*   The generic linear regression model will perform best\n",
        "\n"
      ],
      "metadata": {
        "id": "zxRn8GFD0-pD"
      }
    }
  ]
}